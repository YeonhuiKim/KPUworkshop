{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.3563e-19,  1.3563e-19,  2.0319e-43],\n",
      "        [ 0.0000e+00,  2.5622e+22,  3.0729e-41],\n",
      "        [-6.6111e-39,  4.5768e-41,  1.3563e-19],\n",
      "        [ 1.3563e-19,  1.3563e-19,  1.3563e-19],\n",
      "        [ 1.3563e-19,  1.3563e-19,  1.2456e-11]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.Tensor(5, 3)\n",
    "print(x)\n",
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5230, 0.5670, 0.3396],\n",
      "        [0.0398, 0.1663, 0.3407],\n",
      "        [0.7599, 0.9932, 0.2398],\n",
      "        [0.6819, 0.1788, 0.5259],\n",
      "        [0.2671, 0.5344, 0.9736]])\n",
      "tensor([[ 0.0672,  1.0015, -0.2351],\n",
      "        [-0.8964,  0.6332, -0.2542],\n",
      "        [ 0.6172,  0.8575,  0.0355],\n",
      "        [-0.2817,  1.9219,  0.7750],\n",
      "        [-0.4370, -0.4148, -0.7380]])\n"
     ]
    }
   ],
   "source": [
    "y=torch.rand(5,3)\n",
    "print(y)\n",
    "type(y)\n",
    "yy=torch.randn(5,3)\n",
    "print(yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.3563e-19,  1.3563e-19,  2.0319e-43],\n",
      "        [ 0.0000e+00,  2.5622e+22,  3.0729e-41],\n",
      "        [-6.6111e-39,  4.5768e-41,  1.3563e-19],\n",
      "        [ 1.3563e-19,  1.3563e-19,  1.3563e-19],\n",
      "        [ 1.3563e-19,  1.3563e-19,  1.2456e-11]], dtype=torch.float64)\n",
      "tensor([[0.5230, 0.5670, 0.3396],\n",
      "        [0.0398, 0.1663, 0.3407],\n",
      "        [0.7599, 0.9932, 0.2398],\n",
      "        [0.6819, 0.1788, 0.5259],\n",
      "        [0.2671, 0.5344, 0.9736]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "x=x.double()\n",
    "y=y.double()\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n",
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[-0.1859,  1.3970,  0.5236],\n",
    "                  [ 2.3854,  0.0707,  2.1970],\n",
    "                  [-0.3587,  1.2359,  1.8951],\n",
    "                  [-0.1189, -0.1376,  0.4647],\n",
    "                  [-1.8968,  2.0164,  0.1092]])\n",
    "y = torch.Tensor([[ 0.4838,  0.5822,  0.2755],\n",
    "                  [ 1.0982,  0.4932, -0.6680],\n",
    "                  [ 0.7915,  0.6580, -0.5819],\n",
    "                  [ 0.3825, -1.1822,  1.5217],\n",
    "                  [ 0.6042, -0.2280,  1.3210]])\n",
    "print(x.size())\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5, 3])\n",
      "tensor([[[-0.1859,  1.3970,  0.5236],\n",
      "         [ 2.3854,  0.0707,  2.1970],\n",
      "         [-0.3587,  1.2359,  1.8951],\n",
      "         [-0.1189, -0.1376,  0.4647],\n",
      "         [-1.8968,  2.0164,  0.1092]],\n",
      "\n",
      "        [[ 0.4838,  0.5822,  0.2755],\n",
      "         [ 1.0982,  0.4932, -0.6680],\n",
      "         [ 0.7915,  0.6580, -0.5819],\n",
      "         [ 0.3825, -1.1822,  1.5217],\n",
      "         [ 0.6042, -0.2280,  1.3210]]])\n",
      "tensor([[-0.1859,  1.3970,  0.5236],\n",
      "        [ 2.3854,  0.0707,  2.1970],\n",
      "        [-0.3587,  1.2359,  1.8951],\n",
      "        [-0.1189, -0.1376,  0.4647],\n",
      "        [-1.8968,  2.0164,  0.1092],\n",
      "        [ 0.4838,  0.5822,  0.2755],\n",
      "        [ 1.0982,  0.4932, -0.6680],\n",
      "        [ 0.7915,  0.6580, -0.5819],\n",
      "        [ 0.3825, -1.1822,  1.5217],\n",
      "        [ 0.6042, -0.2280,  1.3210]])\n",
      "tensor([[-0.1859,  1.3970,  0.5236,  0.4838,  0.5822,  0.2755],\n",
      "        [ 2.3854,  0.0707,  2.1970,  1.0982,  0.4932, -0.6680],\n",
      "        [-0.3587,  1.2359,  1.8951,  0.7915,  0.6580, -0.5819],\n",
      "        [-0.1189, -0.1376,  0.4647,  0.3825, -1.1822,  1.5217],\n",
      "        [-1.8968,  2.0164,  0.1092,  0.6042, -0.2280,  1.3210]])\n"
     ]
    }
   ],
   "source": [
    "z=torch.stack((x,y))\n",
    "print(z.size())\n",
    "print(z)\n",
    "print(torch.cat((x,y),0))\n",
    "print(torch.cat((x,y),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3210)\n",
      "tensor(1.3210)\n"
     ]
    }
   ],
   "source": [
    "print(y[4][2])\n",
    "print(z[1][4][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2979,  1.9792,  0.7991],\n",
      "        [ 3.4836,  0.5639,  1.5290],\n",
      "        [ 0.4328,  1.8939,  1.3132],\n",
      "        [ 0.2636, -1.3198,  1.9864],\n",
      "        [-1.2926,  1.7884,  1.4302]])\n",
      "tensor([[ 0.2979,  1.9792,  0.7991],\n",
      "        [ 3.4836,  0.5639,  1.5290],\n",
      "        [ 0.4328,  1.8939,  1.3132],\n",
      "        [ 0.2636, -1.3198,  1.9864],\n",
      "        [-1.2926,  1.7884,  1.4302]])\n",
      "tensor([[ 0.2979,  1.9792,  0.7991],\n",
      "        [ 3.4836,  0.5639,  1.5290],\n",
      "        [ 0.4328,  1.8939,  1.3132],\n",
      "        [ 0.2636, -1.3198,  1.9864],\n",
      "        [-1.2926,  1.7884,  1.4302]])\n",
      "tensor([[ 0.2979,  1.9792,  0.7991],\n",
      "        [ 3.4836,  0.5639,  1.5290],\n",
      "        [ 0.4328,  1.8939,  1.3132],\n",
      "        [ 0.2636, -1.3198,  1.9864],\n",
      "        [-1.2926,  1.7884,  1.4302]])\n"
     ]
    }
   ],
   "source": [
    "print(x+y)\n",
    "print(torch.add(x, y))\n",
    "print(x.add(y))\n",
    "torch.add(x,y,out=x)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "x=torch.randn(4,4)\n",
    "y=x.view(16)\n",
    "z=x.view(-1, 8) # the size -1 is inferred from other dimensions\n",
    "print(x.size(), y.size(), z.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.rand(10,10)\n",
    "y=torch.rand(2, 100)\n",
    "x=x.resize_(1,100)\n",
    "y=y.resize_(100,2)\n",
    "torch.mm(x,y).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1.]\n",
      "<class 'torch.Tensor'> , <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "a=torch.ones(5)\n",
    "print(a)\n",
    "b=a.numpy()\n",
    "print(b)\n",
    "print(str(type(a)),\", \"+str(type(b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 1., 1., 1., 1.])\n",
      "[2. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "a[0]+=1\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5., 4., 4., 4., 4.])\n",
      "[4. 3. 3. 3. 3.]\n"
     ]
    }
   ],
   "source": [
    "a.add_(1)\n",
    "a[:]+=1\n",
    "a=a.add(1)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "a=np.ones(5)\n",
    "b=torch.from_numpy(a)\n",
    "np.add(a, 1, out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "x=torch.randn(5,3).to(device)\n",
    "y=torch.randn(5,3, device=device)\n",
    "z=x+y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.4397949  -1.3521929  -0.05039406]\n",
      " [-2.1495197  -0.21425676 -0.48096612]\n",
      " [ 0.24474624  0.26582742 -0.1951874 ]\n",
      " [ 0.81491077 -0.8785888   0.501112  ]\n",
      " [-0.366535    0.5656759  -1.3306166 ]]\n",
      "[[-0.4397949  -1.3521929  -0.05039406]\n",
      " [-2.1495197  -0.21425676 -0.48096612]\n",
      " [ 0.24474624  0.26582742 -0.1951874 ]\n",
      " [ 0.81491077 -0.8785888   0.501112  ]\n",
      " [-0.366535    0.5656759  -1.3306166 ]]\n"
     ]
    }
   ],
   "source": [
    "print(z.cpu().numpy())\n",
    "print(z.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n",
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x=torch.ones(2,2,requires_grad=True)\n",
    "print(x)\n",
    "y=x+2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z=y*y*3\n",
    "f=z.mean()\n",
    "print(z, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MNISTtools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, ltrain=MNISTtools.load(dataset=\"training\", path=\"../mnist\")\n",
    "xtest, ltest=MNISTtools.load(dataset=\"testing\", path=\"../mnist\")\n",
    "xtrain=xtrain.reshape((28, 28, 1, -1)).astype(np.float32)\n",
    "xtest=xtest.reshape(28, 28, 1, -1).astype(np.float32)\n",
    "xtrain=np.moveaxis(xtrain, [0,1,2,3], [2,3,1,0])\n",
    "xtest=np.moveaxis(xtest, [0,1,2,3], [2,3,1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "MNISTtools.show(xtrain[42, 0, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain=torch.from_numpy(xtrain)\n",
    "ltrain=torch.from_numpy(ltrain)\n",
    "xtest=torch.from_numpy(xtest)\n",
    "ltest=torch.from_numpy(ltest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# This is our neural networks class that inherits from nn.Module\n",
    "class LeNet(nn.Module):\n",
    "\n",
    "    # Here we define our network structure\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1   = nn.Linear(256 ,120)\n",
    "        self.fc2   = nn.Linear(120, 84)\n",
    "        self.fc3   = nn.Linear(84, 10)\n",
    "\n",
    "    # Here we define one forward pass through the network\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    # Determine the number of features in a batch of tensors\n",
    "    def num_flat_features(self, x ):\n",
    "        size = x.size()[1:]\n",
    "        return np.prod(size)\n",
    "\n",
    "net = LeNet()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight torch.Size([6, 1, 5, 5]) True\n",
      "conv1.bias torch.Size([6]) True\n",
      "conv2.weight torch.Size([16, 6, 5, 5]) True\n",
      "conv2.bias torch.Size([16]) True\n",
      "fc1.weight torch.Size([120, 256]) True\n",
      "fc1.bias torch.Size([120]) True\n",
      "fc2.weight torch.Size([84, 120]) True\n",
      "fc2.bias torch.Size([84]) True\n",
      "fc3.weight torch.Size([10, 84]) True\n",
      "fc3.bias torch.Size([10]) True\n"
     ]
    }
   ],
   "source": [
    "for name, param in net.named_parameters():\n",
    "    print(name, param.size(), param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9.9400)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    yinit=net(xtest)\n",
    "_, lpred=yinit.max(1)\n",
    "print(100*(ltest==lpred).float().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop_deep(xtrain, ltrain, net, T, B=100, gamma=.001, rho=.9):\n",
    "    N = xtrain.size()[0]     # Training set size\n",
    "    NB = int((N+B-1)/B)     # Number of minibatches\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=COMPLETE, momentum=rho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# This is our neural networks class that inherits from nn.Module\n",
    "class LeNet(nn.Module):\n",
    "\n",
    "    # Here we define our network structure\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1   = nn.Linear(256 ,120)\n",
    "        self.fc2   = nn.Linear(120, 84)\n",
    "        self.fc3   = nn.Linear(84, 10)\n",
    "\n",
    "    # Here we define one forward pass through the network\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    # Determine the number of features in a batch of tensors\n",
    "    def num_flat_features(self, x ):\n",
    "        size = x.size()[1:]\n",
    "        return np.prod(size)\n",
    "\n",
    "net = LeNet()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight torch.Size([6, 1, 5, 5]) True\n",
      "conv1.bias torch.Size([6]) True\n",
      "conv2.weight torch.Size([16, 6, 5, 5]) True\n",
      "conv2.bias torch.Size([16]) True\n",
      "fc1.weight torch.Size([120, 256]) True\n",
      "fc1.bias torch.Size([120]) True\n",
      "fc2.weight torch.Size([84, 120]) True\n",
      "fc2.bias torch.Size([84]) True\n",
      "fc3.weight torch.Size([10, 84]) True\n",
      "fc3.bias torch.Size([10]) True\n"
     ]
    }
   ],
   "source": [
    "for name, param in net.named_parameters():\n",
    "    print(name, param.size(), param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9.6700)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    yinit=net(xtest)\n",
    "_, lpred = yinit.max(1)\n",
    "print(100 * (ltest == lpred).float().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop_deep(xtrain, ltrain, net, T, B=100, gamma=.001, rho=.9):\n",
    "    N = xtrain.size()[0]     # Training set size\n",
    "    NB = int((N+B-1)/B)     # Number of minibatches\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=0.01, momentum=rho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def backprop_deep(xtrain, ltrain, net, T, B=100, gamma=.001, rho=.9):\n",
    "    N = xtrain.size()[0]     # Training set size\n",
    "    NB = int((N+B-1)/B)     # Number of minibatches\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=0.01, momentum=rho)\n",
    "    \n",
    "    for epoch in range(T):\n",
    "        running_loss = 0.0\n",
    "        shuffled_indices = np.random.permutation(range(N))\n",
    "        for k in range(NB):\n",
    "            # Extract k-th minibatch from xtrain and ltrain\n",
    "            minibatch_indices = shuffled_indices[B*k:min(B*(k+1), N)]\n",
    "            inputs = xtrain[minibatch_indices]\n",
    "            labels = ltrain[minibatch_indices]\n",
    "\n",
    "            # Initialize the gradients to zero\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward propagation\n",
    "            outputs = net(inputs)\n",
    "\n",
    "            # Error evaluation\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Back propagation\n",
    "            loss.backward()\n",
    "\n",
    "            # Parameter update\n",
    "            optimizer.step()\n",
    "\n",
    "            # Print averaged loss per minibatch every 100 mini-batches\n",
    "            # Compute and print statistics\n",
    "            with torch.no_grad():\n",
    "                running_loss += loss.item()\n",
    "            if k % 100 == 99:\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, k + 1, running_loss / 100))\n",
    "                running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 1.270\n",
      "[1,   200] loss: 0.271\n",
      "[1,   300] loss: 0.241\n",
      "[1,   400] loss: 0.186\n",
      "[1,   500] loss: 0.170\n",
      "[1,   600] loss: 0.144\n",
      "[2,   100] loss: 0.144\n",
      "[2,   200] loss: 0.132\n",
      "[2,   300] loss: 0.115\n",
      "[2,   400] loss: 0.123\n",
      "[2,   500] loss: 0.121\n",
      "[2,   600] loss: 0.097\n",
      "[3,   100] loss: 0.091\n",
      "[3,   200] loss: 0.106\n",
      "[3,   300] loss: 0.089\n",
      "[3,   400] loss: 0.100\n",
      "[3,   500] loss: 0.087\n",
      "[3,   600] loss: 0.088\n"
     ]
    }
   ],
   "source": [
    "net = LeNet()\n",
    "backprop_deep(xtrain, ltrain, net, T=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(96.6400)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    yinit=net(xtest)\n",
    "_, lpred = yinit.max(1)\n",
    "print(100 * (ltest == lpred).float().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "net=LeNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 0.921\n",
      "[1,   200] loss: 0.185\n",
      "[1,   300] loss: 0.162\n",
      "[1,   400] loss: 0.134\n",
      "[1,   500] loss: 0.115\n",
      "[1,   600] loss: 0.109\n",
      "[2,   100] loss: 0.086\n",
      "[2,   200] loss: 0.099\n",
      "[2,   300] loss: 0.081\n",
      "[2,   400] loss: 0.081\n",
      "[2,   500] loss: 0.083\n",
      "[2,   600] loss: 0.078\n",
      "[3,   100] loss: 0.061\n",
      "[3,   200] loss: 0.066\n",
      "[3,   300] loss: 0.062\n",
      "[3,   400] loss: 0.069\n",
      "[3,   500] loss: 0.055\n",
      "[3,   600] loss: 0.062\n",
      "[4,   100] loss: 0.054\n",
      "[4,   200] loss: 0.050\n",
      "[4,   300] loss: 0.051\n",
      "[4,   400] loss: 0.057\n",
      "[4,   500] loss: 0.051\n",
      "[4,   600] loss: 0.053\n",
      "[5,   100] loss: 0.037\n",
      "[5,   200] loss: 0.046\n",
      "[5,   300] loss: 0.050\n",
      "[5,   400] loss: 0.046\n",
      "[5,   500] loss: 0.040\n",
      "[5,   600] loss: 0.039\n",
      "[6,   100] loss: 0.034\n",
      "[6,   200] loss: 0.039\n",
      "[6,   300] loss: 0.040\n",
      "[6,   400] loss: 0.040\n",
      "[6,   500] loss: 0.039\n",
      "[6,   600] loss: 0.050\n",
      "[7,   100] loss: 0.034\n",
      "[7,   200] loss: 0.032\n",
      "[7,   300] loss: 0.039\n",
      "[7,   400] loss: 0.044\n",
      "[7,   500] loss: 0.036\n",
      "[7,   600] loss: 0.039\n",
      "[8,   100] loss: 0.040\n",
      "[8,   200] loss: 0.040\n",
      "[8,   300] loss: 0.033\n",
      "[8,   400] loss: 0.030\n",
      "[8,   500] loss: 0.037\n",
      "[8,   600] loss: 0.039\n",
      "[9,   100] loss: 0.022\n",
      "[9,   200] loss: 0.030\n",
      "[9,   300] loss: 0.034\n",
      "[9,   400] loss: 0.044\n",
      "[9,   500] loss: 0.041\n",
      "[9,   600] loss: 0.039\n",
      "[10,   100] loss: 0.026\n",
      "[10,   200] loss: 0.029\n",
      "[10,   300] loss: 0.033\n",
      "[10,   400] loss: 0.036\n",
      "[10,   500] loss: 0.034\n",
      "[10,   600] loss: 0.029\n"
     ]
    }
   ],
   "source": [
    "net2=LeNet().to(device)\n",
    "backprop_deep(xtrain, ltrain, net2, T=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(98.4600)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    yinit=net2(xtest)\n",
    "_, lpred = yinit.max(1)\n",
    "print(100 * (ltest == lpred).float().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
