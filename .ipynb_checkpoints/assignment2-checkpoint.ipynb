{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-7.9896e+29,  3.0890e-41, -6.8184e+30],\n",
      "        [ 3.0890e-41,  1.4013e-45,  0.0000e+00],\n",
      "        [ 2.4734e+00,  2.4404e+00,  5.7979e-01],\n",
      "        [ 3.5449e-02,  7.5689e-01,  6.6007e-02],\n",
      "        [-4.3327e-01, -1.0326e+00,  6.8664e-44]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.Tensor(5, 3)\n",
    "print(x)\n",
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5690, 0.5671, 0.4293],\n",
      "        [0.8146, 0.0543, 0.2607],\n",
      "        [0.8854, 0.1113, 0.1463],\n",
      "        [0.8795, 0.1721, 0.0346],\n",
      "        [0.6066, 0.8795, 0.4741]])\n",
      "tensor([[ 0.8027,  0.2218,  0.1804],\n",
      "        [-0.6275,  0.3804,  0.7486],\n",
      "        [ 0.6678,  0.6804,  1.5958],\n",
      "        [ 1.7758, -0.8945, -1.1951],\n",
      "        [ 1.1876, -0.4553, -1.4833]])\n"
     ]
    }
   ],
   "source": [
    "y=torch.rand(5,3)\n",
    "print(y)\n",
    "type(y)\n",
    "yy=torch.randn(5,3)\n",
    "print(yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-7.9896e+29,  3.0890e-41, -6.8184e+30],\n",
      "        [ 3.0890e-41,  1.4013e-45,  0.0000e+00],\n",
      "        [ 2.4734e+00,  2.4404e+00,  5.7979e-01],\n",
      "        [ 3.5449e-02,  7.5689e-01,  6.6007e-02],\n",
      "        [-4.3327e-01, -1.0326e+00,  6.8664e-44]], dtype=torch.float64)\n",
      "tensor([[0.5690, 0.5671, 0.4293],\n",
      "        [0.8146, 0.0543, 0.2607],\n",
      "        [0.8854, 0.1113, 0.1463],\n",
      "        [0.8795, 0.1721, 0.0346],\n",
      "        [0.6066, 0.8795, 0.4741]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "x=x.double()\n",
    "y=y.double()\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n",
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[-0.1859,  1.3970,  0.5236],\n",
    "                  [ 2.3854,  0.0707,  2.1970],\n",
    "                  [-0.3587,  1.2359,  1.8951],\n",
    "                  [-0.1189, -0.1376,  0.4647],\n",
    "                  [-1.8968,  2.0164,  0.1092]])\n",
    "y = torch.Tensor([[ 0.4838,  0.5822,  0.2755],\n",
    "                  [ 1.0982,  0.4932, -0.6680],\n",
    "                  [ 0.7915,  0.6580, -0.5819],\n",
    "                  [ 0.3825, -1.1822,  1.5217],\n",
    "                  [ 0.6042, -0.2280,  1.3210]])\n",
    "print(x.size())\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5, 3])\n",
      "tensor([[[-0.1859,  1.3970,  0.5236],\n",
      "         [ 2.3854,  0.0707,  2.1970],\n",
      "         [-0.3587,  1.2359,  1.8951],\n",
      "         [-0.1189, -0.1376,  0.4647],\n",
      "         [-1.8968,  2.0164,  0.1092]],\n",
      "\n",
      "        [[ 0.4838,  0.5822,  0.2755],\n",
      "         [ 1.0982,  0.4932, -0.6680],\n",
      "         [ 0.7915,  0.6580, -0.5819],\n",
      "         [ 0.3825, -1.1822,  1.5217],\n",
      "         [ 0.6042, -0.2280,  1.3210]]])\n",
      "tensor([[-0.1859,  1.3970,  0.5236],\n",
      "        [ 2.3854,  0.0707,  2.1970],\n",
      "        [-0.3587,  1.2359,  1.8951],\n",
      "        [-0.1189, -0.1376,  0.4647],\n",
      "        [-1.8968,  2.0164,  0.1092],\n",
      "        [ 0.4838,  0.5822,  0.2755],\n",
      "        [ 1.0982,  0.4932, -0.6680],\n",
      "        [ 0.7915,  0.6580, -0.5819],\n",
      "        [ 0.3825, -1.1822,  1.5217],\n",
      "        [ 0.6042, -0.2280,  1.3210]])\n",
      "tensor([[-0.1859,  1.3970,  0.5236,  0.4838,  0.5822,  0.2755],\n",
      "        [ 2.3854,  0.0707,  2.1970,  1.0982,  0.4932, -0.6680],\n",
      "        [-0.3587,  1.2359,  1.8951,  0.7915,  0.6580, -0.5819],\n",
      "        [-0.1189, -0.1376,  0.4647,  0.3825, -1.1822,  1.5217],\n",
      "        [-1.8968,  2.0164,  0.1092,  0.6042, -0.2280,  1.3210]])\n"
     ]
    }
   ],
   "source": [
    "z=torch.stack((x,y))\n",
    "print(z.size())\n",
    "print(z)\n",
    "print(torch.cat((x,y),0))\n",
    "print(torch.cat((x,y),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3210)\n",
      "tensor(1.3210)\n"
     ]
    }
   ],
   "source": [
    "print(y[4][2])\n",
    "print(z[1][4][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2979,  1.9792,  0.7991],\n",
      "        [ 3.4836,  0.5639,  1.5290],\n",
      "        [ 0.4328,  1.8939,  1.3132],\n",
      "        [ 0.2636, -1.3198,  1.9864],\n",
      "        [-1.2926,  1.7884,  1.4302]])\n",
      "tensor([[ 0.2979,  1.9792,  0.7991],\n",
      "        [ 3.4836,  0.5639,  1.5290],\n",
      "        [ 0.4328,  1.8939,  1.3132],\n",
      "        [ 0.2636, -1.3198,  1.9864],\n",
      "        [-1.2926,  1.7884,  1.4302]])\n",
      "tensor([[ 0.2979,  1.9792,  0.7991],\n",
      "        [ 3.4836,  0.5639,  1.5290],\n",
      "        [ 0.4328,  1.8939,  1.3132],\n",
      "        [ 0.2636, -1.3198,  1.9864],\n",
      "        [-1.2926,  1.7884,  1.4302]])\n",
      "tensor([[ 0.2979,  1.9792,  0.7991],\n",
      "        [ 3.4836,  0.5639,  1.5290],\n",
      "        [ 0.4328,  1.8939,  1.3132],\n",
      "        [ 0.2636, -1.3198,  1.9864],\n",
      "        [-1.2926,  1.7884,  1.4302]])\n"
     ]
    }
   ],
   "source": [
    "print(x+y)\n",
    "print(torch.add(x, y))\n",
    "print(x.add(y))\n",
    "torch.add(x,y,out=x)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "x=torch.randn(4,4)\n",
    "y=x.view(16)\n",
    "z=x.view(-1, 8) # the size -1 is inferred from other dimensions\n",
    "print(x.size(), y.size(), z.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.rand(10,10)\n",
    "y=torch.rand(2, 100)\n",
    "x=x.resize_(1,100)\n",
    "y=y.resize_(100,2)\n",
    "torch.mm(x,y).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1.]\n",
      "<class 'torch.Tensor'> , <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "a=torch.ones(5)\n",
    "print(a)\n",
    "b=a.numpy()\n",
    "print(b)\n",
    "print(str(type(a)),\", \"+str(type(b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 1., 1., 1., 1.])\n",
      "[2. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "a[0]+=1\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5., 4., 4., 4., 4.])\n",
      "[4. 3. 3. 3. 3.]\n"
     ]
    }
   ],
   "source": [
    "a.add_(1)\n",
    "a[:]+=1\n",
    "a=a.add(1)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "a=np.ones(5)\n",
    "b=torch.from_numpy(a)\n",
    "np.add(a, 1, out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "x=torch.randn(5,3).to(device)\n",
    "y=torch.randn(5,3, device=device)\n",
    "z=x+y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.15765476 -1.8473871  -1.2226509 ]\n",
      " [-0.4877494  -0.07124931  2.2233171 ]\n",
      " [-1.4597634  -1.905862    0.49495807]\n",
      " [ 0.99527246  0.3703445  -0.53881246]\n",
      " [-1.798619    2.3877478  -0.24352151]]\n",
      "[[ 0.15765476 -1.8473871  -1.2226509 ]\n",
      " [-0.4877494  -0.07124931  2.2233171 ]\n",
      " [-1.4597634  -1.905862    0.49495807]\n",
      " [ 0.99527246  0.3703445  -0.53881246]\n",
      " [-1.798619    2.3877478  -0.24352151]]\n"
     ]
    }
   ],
   "source": [
    "print(z.cpu().numpy())\n",
    "print(z.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n",
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x=torch.ones(2,2,requires_grad=True)\n",
    "print(x)\n",
    "y=x+2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z=y*y*3\n",
    "f=z.mean()\n",
    "print(z, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MNISTtools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, ltrain=MNISTtools.load(dataset=\"training\", path=\"../mnist\")\n",
    "xtest, ltest=MNISTtools.load(dataset=\"testing\", path=\"../mnist\")\n",
    "xtrain=xtrain.reshape((28, 28, 1, -1)).astype(np.float32)\n",
    "xtest=xtest.reshape(28, 28, 1, -1).astype(np.float32)\n",
    "xtrain=np.moveaxis(xtrain, -1, 0)\n",
    "xtrain=np.moveaxis(xtrain, -1, 1)\n",
    "xtest=np.moveaxis(xtest, -1, 0)\n",
    "xtest=np.moveaxis(xtest, -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "MNISTtools.show(xtrain[42, 0, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain=torch.from_numpy(xtrain)\n",
    "ltrain=torch.from_numpy(ltrain)\n",
    "xtest=torch.from_numpy(xtest)\n",
    "ltest=torch.from_numpy(ltest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# This is our neural networks class that inherits from nn.Module\n",
    "class LeNet(nn.Module):\n",
    "\n",
    "    # Here we define our network structure\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1   = nn.Linear(256 ,120)\n",
    "        self.fc2   = nn.Linear(120, 84)\n",
    "        self.fc3   = nn.Linear(84, 10)\n",
    "\n",
    "    # Here we define one forward pass through the network\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    # Determine the number of features in a batch of tensors\n",
    "    def num_flat_features(self, x ):\n",
    "        size = x.size()[1:]\n",
    "        return np.prod(size)\n",
    "\n",
    "net = LeNet()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight torch.Size([6, 1, 5, 5]) True\n",
      "conv1.bias torch.Size([6]) True\n",
      "conv2.weight torch.Size([16, 6, 5, 5]) True\n",
      "conv2.bias torch.Size([16]) True\n",
      "fc1.weight torch.Size([120, 256]) True\n",
      "fc1.bias torch.Size([120]) True\n",
      "fc2.weight torch.Size([84, 120]) True\n",
      "fc2.bias torch.Size([84]) True\n",
      "fc3.weight torch.Size([10, 84]) True\n",
      "fc3.bias torch.Size([10]) True\n"
     ]
    }
   ],
   "source": [
    "for name, param in net.named_parameters():\n",
    "    print(name, param.size(), param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.1800)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    yinit=net(xtest)\n",
    "_, lpred=yinit.max(1)\n",
    "print(100*(ltest==lpred).float().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop_deep(xtrain, ltrain, net, T, B=100, gamma=.001, rho=.9):\n",
    "    N = xtrain.size()[0]     # Training set size\n",
    "    NB = int((N+B-1)/B)     # Number of minibatches\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=COMPLETE, momentum=rho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# This is our neural networks class that inherits from nn.Module\n",
    "class LeNet(nn.Module):\n",
    "\n",
    "    # Here we define our network structure\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1   = nn.Linear(256 ,120)\n",
    "        self.fc2   = nn.Linear(120, 84)\n",
    "        self.fc3   = nn.Linear(84, 10)\n",
    "\n",
    "    # Here we define one forward pass through the network\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    # Determine the number of features in a batch of tensors\n",
    "    def num_flat_features(self, x ):\n",
    "        size = x.size()[1:]\n",
    "        return np.prod(size)\n",
    "\n",
    "net = LeNet()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight torch.Size([6, 1, 5, 5]) True\n",
      "conv1.bias torch.Size([6]) True\n",
      "conv2.weight torch.Size([16, 6, 5, 5]) True\n",
      "conv2.bias torch.Size([16]) True\n",
      "fc1.weight torch.Size([120, 256]) True\n",
      "fc1.bias torch.Size([120]) True\n",
      "fc2.weight torch.Size([84, 120]) True\n",
      "fc2.bias torch.Size([84]) True\n",
      "fc3.weight torch.Size([10, 84]) True\n",
      "fc3.bias torch.Size([10]) True\n"
     ]
    }
   ],
   "source": [
    "for name, param in net.named_parameters():\n",
    "    print(name, param.size(), param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(93.7700)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    yinit=net(xtest)\n",
    "_, lpred = yinit.max(1)\n",
    "print(100 * (ltest == lpred).float().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop_deep(xtrain, ltrain, net, T, B=100, gamma=.001, rho=.9):\n",
    "    N = xtrain.size()[0]     # Training set size\n",
    "    NB = int((N+B-1)/B)     # Number of minibatches\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=0.01, momentum=rho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 1.731\n",
      "[1,   200] loss: 0.728\n",
      "[1,   300] loss: 0.517\n",
      "[1,   400] loss: 0.397\n",
      "[1,   500] loss: 0.334\n",
      "[1,   600] loss: 0.236\n",
      "[2,   100] loss: 0.231\n",
      "[2,   200] loss: 0.240\n",
      "[2,   300] loss: 0.207\n",
      "[2,   400] loss: 0.213\n",
      "[2,   500] loss: 0.190\n",
      "[2,   600] loss: 0.137\n",
      "[3,   100] loss: 0.156\n",
      "[3,   200] loss: 0.167\n",
      "[3,   300] loss: 0.143\n",
      "[3,   400] loss: 0.151\n",
      "[3,   500] loss: 0.143\n",
      "[3,   600] loss: 0.114\n"
     ]
    }
   ],
   "source": [
    "def backprop_deep(xtrain, ltrain, net, T, B=100, gamma=.001, rho=.9):\n",
    "    N = xtrain.size()[0]     # Training set size\n",
    "    NB = int((N+B-1)/B)     # Number of minibatches\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=0.01, momentum=rho)\n",
    "    \n",
    "    for epoch in range(T):\n",
    "        running_loss = 0.0\n",
    "        shuffled_indices = np.random.permutation(range(N))\n",
    "        for k in range(NB):\n",
    "            # Extract k-th minibatch from xtrain and ltrain\n",
    "            minibatch_indices = shuffled_indices[B*k:min(B*(k+1), N)]\n",
    "            index=np.arange(B*k, min(B*(k+1), N))\n",
    "            inputs = xtrain[index]\n",
    "            labels = ltrain[index]\n",
    "\n",
    "            # Initialize the gradients to zero\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward propagation\n",
    "            outputs = net(inputs)\n",
    "\n",
    "            # Error evaluation\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Back propagation\n",
    "            loss.backward()\n",
    "\n",
    "            # Parameter update\n",
    "            optimizer.step()\n",
    "\n",
    "            # Print averaged loss per minibatch every 100 mini-batches\n",
    "            # Compute and print statistics\n",
    "            with torch.no_grad():\n",
    "                running_loss += loss.item()\n",
    "            if k % 100 == 99:\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, k + 1, running_loss / 100))\n",
    "                running_loss = 0.0\n",
    "\n",
    "net = LeNet()\n",
    "backprop_deep(xtrain, ltrain, net, T=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
